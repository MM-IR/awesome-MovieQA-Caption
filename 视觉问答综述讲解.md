# 根据视觉媒介的不同，通常可分为基于图像的问答与推理/基于视频的问答与推理/基于视觉常识的问答与推理。
对于基本的视觉问答系统通常包括了对于视觉和语言两个模态的表征/跨模态融合/问答推理3个步骤。

核心:

1.跨模态融合;

2.问答推理。

### 常见的融合方法。
1.除了multimodal pooling以外，提出双线性融合，这样能够充分包含各种模态信息的融合表示，从而提升了视觉问答任务的性能。

2.注意力机制。**视觉可解释性**

3.除了基于自然图像和视频的视觉问答与推理，这里还包括了医疗图像问答和视觉对话系统的研究。

# 2.图像的视觉问答与推理
1.有效的融合方法来获得视觉和语言的联合表达；**从而任务的性能**；

2.借助注意力机制来捕捉与问题相关的视觉信息。

3.基于提取的视觉和语言表示，设计一种有效的推理方法来推出准确的答案选项。

## 2.1 多模态融合的视觉问答方法
这个的目的是能得到一个尽可能包含各种模态信息的紧凑表示。

1.早期工作主要基于一阶交互的思想来促进视觉-语言两种模态的融合；concat/注意里机制/相互注意力。

2.二阶交互，对应元素乘积，MCB就是基于视觉和文本表示首先进行外积运算，然后通过一个非线性变换，将外积运算的结果映射到一个低纬度的空间。**但是这种方法一般只是针对高dim度的特征具有明显效果**

3.因此，MLB就是低rank双线性融合来做，**效果比MCB要好，还可以有更小的计算量。**

4.Ben提出一种新的机遇双线性交互的多模态融合方法，即MUTAN。**控制模型的参数数量，MUTAn可以减小特征的嵌入特征矩阵的尺寸**

5.Yu的MFB同样地

6.Ben就是提出一种基于块超对角线张量分解的融合算法，进一步提升视觉-语言融合的效果以及视觉问答任务的性能。

## 2.2 基于注意力机制的视觉问答方法
TODO

## 2.3 视觉问答与推理
2.3.1 Neural Module Networks

2.3.2 实体关联的推理

这个就是考虑图片中各个实体间的关系来推导正确的答案。

2.3.3 基于图网络的推理

# 3.基于视频的VQA与reasoning
## 3.1. 基于记忆网络的方法
核心就是看看progressive那篇文章，这里就是可以利用问题和答案中的线索逐步删减内存中无关的时间片段，从而提升了任务的性能。

## 3.2。 基于协同注意力的方法

# 4.视觉常识的推理
目前bert取得了最好的结果。






# 6.最重要的就是咱们的研究展望啦。
1) 高效的多模态融合方法: 多模态融合是跨模态的基础研究问题。**目前常用的跨模态方法的目的仍然是让多模态特征元素之间充分交互。但是，这个随着特征维度的增加，这种方法的计算量会增大。**

同时这种方法并不能保证所得到的融合特征包含与任务相关的信息...

因此如何设计一个任务-specific特征融合。**不太懂，一个linear层还不是task-specific**

2) 准确的语言单词嵌入和视觉特征提取。task-specific

**如何把单词嵌入矩阵和视觉特征提取网络与任务一起训练是一个值得研究的问题。**

3)对于基于视频的视觉问答与推理，更长的视频内容就对记忆和推理能力起到了很大的挑战。**细粒度理解和外部知识**

这个就是记忆网络模块可能不一定够用，目前视频问答技术正从简单的感知层面向更进一步的认知推理层面迈进，对于正确的答案的预测**不能仅仅依赖视觉或者文本内容的共现性**，而更佳应该具备对视频内容的细粒度理解。**如何在视频问答时结合外部知识并提供先验知识**。

4)高效的推理算法

推理往往是方向性的，可是**这类方向采用的只是无向网络**。+全连接的图网络往往增加了计算量。


5）可解释的推理算法
可解释性的模型还是蛮有意义的。



